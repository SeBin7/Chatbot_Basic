
version: '3.8'
services:
  backend_dev:
    image: mychat-backend:dev
    build:
      context: ./backend
      dockerfile: Dockerfile
    env_file:
      - ./backend/.env
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./vector_store:/app/vector_store
      - /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:ro
      - /opt/intel/oneapi:/opt/intel/oneapi:ro
    networks:
      - app_network
    environment:
      OLLAMA_BASE_URL: http://ollama_dev:11434
      PIP_INDEX_URL: https://pypi.tuna.tsinghua.edu.cn/simple
      PIP_TRUSTED_HOST: pypi.tuna.tsinghua.edu.cn
      LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/opt/intel/oneapi:$LD_LIBRARY_PATH
      LIBVA_DRIVER_NAME: iHD
      ONEAPI_DEVICE_SELECTOR: level_zero:gpu
    privileged: true
    security_opt:
      - seccomp=unconfined
    devices:
      - /dev/dri:/dev/dri
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    tty: true
    stdin_open: true

  react_dev:
    image: mychat-frontend:dev
    build:
      context: ./frontend
      dockerfile: Dockerfile
    env_file:
      - ./frontend/.env.development
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      REACT_APP_URL: http://192.168.100.41:3000
      REACT_APP_API_URL: http://192.168.100.41:8000
      DISABLE_ESLINT_PLUGIN: "true"
      CI: "false"
      NODE_OPTIONS: "--dns-result-order=ipv4first"
    networks:
      - app_network

  ollama_dev:
    image: mychat-ollama:dev
    build:
      context: ./ollama
      dockerfile: Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ./ollama/models:/models
      - /home/se/Downloads/ollama-ipex-llm-2.2.0-ubuntu:/ollama-ipex
      - /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:ro
      - /opt/intel/oneapi:/opt/intel/oneapi:ro
    devices:
      - /dev/dri:/dev/dri
    privileged: true
    environment:
      - ZE_AFFINITY_MASK=0
      - OLLAMA_INTEL_GPU=1
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_GPU_DEVICE=0
      - OLLAMA_LLM_LIBRARY=oneapi
      - LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
      - ONEAPI_DEVICE_SELECTOR=level_zero:gpu
    networks:
      - app_network

networks:
  app_network:
    driver: bridge